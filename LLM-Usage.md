# LLM Usage Disclosure

This project was developed with the assistance of Large Language Models (LLMs), but **not generated by them**. The architecture, API design, type system choices, and core logic reflect deliberate engineering decisions made by the human author.

## Nature of LLM Involvement

- **Pair programming & design discussions**: LLMs were used interactively to explore Rust idioms, trait design patterns, lifetime issues, and numerical stability considerations.
- **Code suggestions**: Small code snippets (e.g., iterator implementations, macro sketches, error handling) were sometimes proposed by an LLM and then **critically reviewed, modified, or rejected** by the developer.
- **Debugging aid**: LLMs helped interpret compiler errors (especially around lifetimes and associated types) and suggested plausible fixes—always verified manually.
- **Documentation drafting**: Some comments and docstrings were drafted with LLM help and then edited for accuracy.

## What Was *Not* Done

- No file or module was auto-generated end-to-end by an LLM.
- No architectural decision (e.g., separating `Trainer`, `Loss`, and `Model`) was delegated to an LLM.
- All performance-critical and safety-critical code (e.g., tensor operations, gradient computation) was written and validated by hand.

## Philosophy

This project follows a **human-in-the-loop** approach:  
> *"The LLM is a knowledgeable but fallible junior collaborator—useful for brainstorming and boilerplate, never for final judgment."*

The goal is **correctness, clarity, and maintainability**, not automation for its own sake.

---
*Last updated: January 2026*